{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install expelliarmus --quiet\n",
    "# %pip install aedat --quiet\n",
    "# %pip install loris --quiet\n",
    "# %pip install brotli --quiet\n",
    "# %pip install h5py --quiet\n",
    "# %pip install numpy --quiet\n",
    "\n",
    "from expelliarmus import Wizard\n",
    "import aedat\n",
    "import pathlib\n",
    "import h5py\n",
    "import numpy as np\n",
    "import timeit\n",
    "import requests\n",
    "import pickle\n",
    "import os\n",
    "import loris\n",
    "import brotli\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fname = \"driving_sample\"\n",
    "fname = \"construction\"  # use this one if you want to include aedat benchmarks\n",
    "\n",
    "# where to download and generate all the benchmark data\n",
    "folder = Path(\"data/file-benchmark\")\n",
    "folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# key is the name of the encoding, value is the file name ending\n",
    "extension_map = {\n",
    "    \"aedat\": \".aedat4\",\n",
    "    \"dat\": \".dat\",\n",
    "    \"evt2\": \"_evt2.raw\",\n",
    "    \"evt3\": \"_evt3.raw\",\n",
    "    \"hdf5\": \".hdf5\",\n",
    "    \"hdf5_lzf\": \"_lzf.hdf5\",\n",
    "    \"hdf5_gzip\": \"_gzip.hdf5\",\n",
    "    \"numpy\": \".npy\",\n",
    "    \"eventstream\": \".es\",\n",
    "    \"brotli\": \".bin.br\",\n",
    "}\n",
    "get_fpath = lambda encoding: f\"{folder}/{fname}{extension_map[encoding]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m decoder \u001b[38;5;241m=\u001b[39m aedat\u001b[38;5;241m.\u001b[39mDecoder(get_fpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maedat\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     36\u001b[0m events \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m---> 37\u001b[0m     [packet[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevents\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m packet \u001b[38;5;129;01min\u001b[39;00m decoder \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevents\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m packet]\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m data \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m     40\u001b[0m     np\u001b[38;5;241m.\u001b[39mdtype([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i8\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i2\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i2\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m\"\u001b[39m)], align\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m )\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m decoder \u001b[38;5;241m=\u001b[39m aedat\u001b[38;5;241m.\u001b[39mDecoder(get_fpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maedat\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     36\u001b[0m events \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m---> 37\u001b[0m     [packet[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevents\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m packet \u001b[38;5;129;01min\u001b[39;00m decoder \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevents\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m packet]\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m data \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m     40\u001b[0m     np\u001b[38;5;241m.\u001b[39mdtype([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i8\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i2\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i2\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu1\u001b[39m\u001b[38;5;124m\"\u001b[39m)], align\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if fname == \"driving_sample\":\n",
    "    if not os.path.exists(get_fpath(\"evt3\")):\n",
    "        print(\"Downloading EVT3 file... \", end=\"\")\n",
    "        if not pathlib.Path(get_fpath(\"evt3\")).is_file():\n",
    "            r = requests.get(\n",
    "                \"https://dataset.prophesee.ai/index.php/s/nVcLLdWAnNzrmII/download\",\n",
    "                allow_redirects=True,\n",
    "            )\n",
    "            open(get_fpath(\"evt3\"), \"wb\").write(r.content)\n",
    "        print(\"done!\")\n",
    "\n",
    "    wizard = Wizard(encoding=\"evt3\")\n",
    "    data = wizard.read(get_fpath(\"evt3\"))\n",
    "\n",
    "\n",
    "if fname == \"construction\":\n",
    "    if not os.path.exists(get_fpath(\"aedat\")):\n",
    "        print(\"Downloading aedat4 file... \", end=\"\")\n",
    "        if not pathlib.Path(get_fpath(\"aedat\")).is_file():\n",
    "            r = requests.get(\n",
    "                \"https://cloudstor.aarnet.edu.au/plus/s/ORQ2oOz9NfwiHLZ/download?path=%2F&files=construction.aedat4\",\n",
    "                allow_redirects=True,\n",
    "            )\n",
    "            open(get_fpath(\"aedat\"), \"wb\").write(r.content)\n",
    "    if not os.path.exists(get_fpath(\"eventstream\")):\n",
    "        print(\"Downloading eventstream file... \", end=\"\")\n",
    "        if not pathlib.Path(get_fpath(\"eventstream\")).is_file():\n",
    "            r = requests.get(\n",
    "                \"https://cloudstor.aarnet.edu.au/plus/s/ORQ2oOz9NfwiHLZ/download?path=%2F&files=construction.es\",\n",
    "                allow_redirects=True,\n",
    "            )\n",
    "            open(get_fpath(\"eventstream\"), \"wb\").write(r.content)\n",
    "        print(\"done!\")\n",
    "\n",
    "    decoder = aedat.Decoder(get_fpath(\"aedat\"))\n",
    "    events = np.concatenate(\n",
    "        [packet[\"events\"] for packet in decoder if \"events\" in packet]\n",
    "    )\n",
    "    data = events.astype(\n",
    "        np.dtype([(\"t\", \"<i8\"), (\"x\", \"<i2\"), (\"y\", \"<i2\"), (\"p\", \"u1\")], align=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Generate all comparison files\n",
    "\n",
    "# evt2 and dat\n",
    "raw_encodings = [\"dat\", \"evt2\", \"evt3\"]\n",
    "for encoding in raw_encodings:\n",
    "    if not os.path.exists(get_fpath(encoding)):\n",
    "        print(f\"Generating file for {encoding} encoding.\")\n",
    "        wizard = Wizard(encoding=encoding)\n",
    "        wizard.save(fpath=get_fpath(encoding), arr=data)\n",
    "\n",
    "# variants of hdf5\n",
    "hdf5_encodings = [\"hdf5\", \"hdf5_lzf\", \"hdf5_gzip\"]\n",
    "for encoding in hdf5_encodings:\n",
    "    fpath = get_fpath(encoding)\n",
    "    if not os.path.exists(fpath):\n",
    "        with h5py.File(fpath, \"w\") as fp:\n",
    "            print(f\"Generating file for {encoding} encoding.\")\n",
    "            dataset_dict = dict(\n",
    "                name=\"events\",\n",
    "                shape=data.shape,\n",
    "                dtype=data.dtype,\n",
    "                data=data,\n",
    "            )\n",
    "            if encoding == \"hdf5\":\n",
    "                fp.create_dataset(**dataset_dict)\n",
    "            elif encoding == \"hdf5_lzf\":\n",
    "                fp.create_dataset(**dataset_dict, compression=\"lzf\")\n",
    "            elif encoding == \"hdf5_gzip\":\n",
    "                fp.create_dataset(**dataset_dict, compression=\"gzip\")\n",
    "\n",
    "# numpy\n",
    "fpath = get_fpath(\"numpy\")\n",
    "if not os.path.exists(fpath):\n",
    "    print(f\"Generating file for numpy encoding.\")\n",
    "    np.save(fpath, data, allow_pickle=True)\n",
    "\n",
    "# brotli\n",
    "if not os.path.exists(get_fpath(\"brotli\")):\n",
    "    print(f\"Generating file for brotli encoding.\")\n",
    "    with open(get_fpath(\"brotli\")+\".tmp\", \"wb\") as out_file:\n",
    "        with open(get_fpath(\"dat\"), \"rb\") as in_file:\n",
    "            buff = in_file.read()\n",
    "            cnt, i = 0, 0\n",
    "            while (cnt < 3):\n",
    "                cnt += 1 if buff[i]==0x0A else 0\n",
    "                i += 1\n",
    "            out_file.write(buff[i:])\n",
    "    with open(get_fpath(\"brotli\"), \"wb\") as out_file:\n",
    "        with open(get_fpath(\"brotli\")+\".tmp\", \"rb\") as in_file:\n",
    "            in_file.read(2)\n",
    "            out_file.write(brotli.compress(in_file.read(), quality=5))\n",
    "    os.remove(get_fpath(\"brotli\")+\".tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking expelliarmus.\n",
      "Benchmarking HDF5.\n",
      "Benchmarking NumPy.\n"
     ]
    }
   ],
   "source": [
    "## Run benchmarks\n",
    "\n",
    "REPEAT = 10\n",
    "get_fsize_MB = lambda fpath: round(fpath.stat().st_size / (1024 * 1024))\n",
    "arr = None\n",
    "\n",
    "# evt2, evt3, dat\n",
    "print(\"Benchmarking expelliarmus.\")\n",
    "raw_times = []\n",
    "raw_sizes = []\n",
    "for encoding in raw_encodings:\n",
    "    fpath = get_fpath(encoding)\n",
    "    wizard = Wizard(encoding)\n",
    "    wizard.set_file(fpath)\n",
    "    \n",
    "    def fn():\n",
    "        arr = wizard.read(fpath)\n",
    "        \n",
    "    raw_times.append(\n",
    "        sum(timeit.repeat(fn, number=1, repeat=REPEAT)) / REPEAT\n",
    "    )\n",
    "    raw_sizes.append(get_fsize_MB(pathlib.Path(fpath)))\n",
    "\n",
    "# hdf5 variants\n",
    "print(\"Benchmarking HDF5.\")\n",
    "hdf5_times = []\n",
    "hdf5_sizes = []\n",
    "for encoding in hdf5_encodings:\n",
    "    fpath = get_fpath(encoding)\n",
    "    fp = h5py.File(fpath)\n",
    "    \n",
    "    def fn(): \n",
    "        arr = fp[\"events\"][:]\n",
    "    \n",
    "    hdf5_times.append(\n",
    "        sum(timeit.repeat(fn, number=1, repeat=REPEAT)) / REPEAT\n",
    "    )\n",
    "    fp.close()\n",
    "    hdf5_sizes.append(get_fsize_MB(pathlib.Path(fpath)))\n",
    "\n",
    "# numpy\n",
    "print(\"Benchmarking NumPy.\")\n",
    "fpath = get_fpath(\"numpy\")\n",
    "\n",
    "def fn(): \n",
    "    arr = np.load(fpath)\n",
    "    \n",
    "numpy_time = (\n",
    "    sum(timeit.repeat(fn , number=1, repeat=REPEAT)) / REPEAT\n",
    ")\n",
    "numpy_size = get_fsize_MB(pathlib.Path(fpath))\n",
    "\n",
    "# aedat4\n",
    "print(\"Benchmarking AEDAT.\")\n",
    "fpath = get_fpath(\"aedat\")\n",
    "\n",
    "def fn():\n",
    "    arr = [packet[\"events\"] for packet in aedat.Decoder(fpath) if \"events\" in packet]\n",
    "\n",
    "aedat_time = (\n",
    "    sum(timeit.repeat(fn, number=1, repeat=REPEAT)) / REPEAT\n",
    ")\n",
    "aedat_size = get_fsize_MB(pathlib.Path(fpath))\n",
    "\n",
    "# eventstream\n",
    "print(\"Benchmarking eventstream.\")\n",
    "fpath = get_fpath(\"eventstream\")\n",
    "\n",
    "def fn():\n",
    "    arr = loris.read_file(fpath)\n",
    "    \n",
    "es_time = (\n",
    "    sum(timeit.repeat(fn, number=1, repeat=REPEAT)) / REPEAT\n",
    ")\n",
    "es_size = get_fsize_MB(pathlib.Path(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking brotli.\n",
      "29.49, 447\n"
     ]
    }
   ],
   "source": [
    "# brotli\n",
    "print(\"Benchmarking brotli.\")\n",
    "fpath = get_fpath(\"brotli\")\n",
    "dtype = np.dtype([(\"t\", \"<i8\"), (\"x\", \"<i2\"), (\"y\", \"<i2\"), (\"p\", \"u1\")])\n",
    "\n",
    "\n",
    "def brotli_read():\n",
    "    # Reading to a numpy buffer the data.\n",
    "    with open(fpath, \"rb\") as fp:\n",
    "        np_buff = np.frombuffer(\n",
    "            brotli.decompress(fp.read()), dtype=np.uint64\n",
    "        )  # , align=True)\n",
    "\n",
    "    # Creating the structured NumPy array.\n",
    "    arr = np.empty(len(np_buff), dtype=dtype)\n",
    "\n",
    "    # Decoding the buffer.\n",
    "    arr[\"t\"] = np_buff & 0xFFFFFFFF  # 32 bits\n",
    "    arr[\"x\"] = (np_buff >> (64 - 32)) & 0x3FFF  # 14 bits\n",
    "    arr[\"y\"] = (np_buff >> (64 - (32 + 14))) & 0x3FFF  # 14 bits\n",
    "    arr[\"p\"] = np_buff >> (64 - (32 + 28))\n",
    "\n",
    "brotli_time = sum(timeit.repeat(brotli_read, number=1, repeat=REPEAT)) / REPEAT\n",
    "brotli_size = get_fsize_MB(pathlib.Path(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Aggregate results\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Encoding\": raw_encodings\n",
    "        + hdf5_encodings\n",
    "        + [\"numpy\", \"aedat4\", \"eventstream\"],  # , \"dat/brotli\"],\n",
    "        \"Framework\": [\"expelliarmus\"] * len(raw_encodings)\n",
    "        + [\"h5py\"] * len(hdf5_encodings)\n",
    "        + [\"numpy\", \"aedat\", \"loris\"],  # \"expelliarmus/brotli\"],\n",
    "        \"Read time [s]\": raw_times\n",
    "        + hdf5_times\n",
    "        + [numpy_time, aedat_time, es_time],  # brotli_time],\n",
    "        \"File size [MB]\": raw_sizes\n",
    "        + hdf5_sizes\n",
    "        + [numpy_size, aedat_size, es_size],  # brotli_size],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot results\n",
    "\n",
    "import plotly.express as px\n",
    "from IPython.display import Image\n",
    "\n",
    "title = f\"Reading the same {int(len(data)/1e6)} million events from different files.\"\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"Read time [s]\",\n",
    "    y=\"File size [MB]\",\n",
    "    color=\"Framework\",\n",
    "    symbol=\"Encoding\",\n",
    "    title=title,\n",
    "    template=\"plotly_dark\",\n",
    ")\n",
    "fig.update_traces(marker_size=13)\n",
    "fig.write_image(\"file_read_benchmark.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c00e5e7c7a569083cb991dfa106f557879cc0d1d84bf5b9d92fbb6bf680d358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
