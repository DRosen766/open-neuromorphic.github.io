{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "Start with creating a new Conda environment\n",
    "```\n",
    "conda create -n frameworks pip\n",
    "conda activate frameworks\n",
    "```\n",
    "Then install PyTorch (adjust for your CUDA version). Instructions available [here](https://pytorch.org/get-started/locally/)\n",
    "```\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    "```\n",
    "Install the benchmarked frameworks from PyPI\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "This benchmark code is an adaptation of Rockpool's [benchmark script](https://gitlab.com/synsense/rockpool/-/blob/develop/rockpool/utilities/benchmarking/benchmark_utils.py?ref_type=heads). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utils import timeit, benchmark_framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rockpool_torch():\n",
    "    from rockpool.nn.modules import LIFTorch, LinearTorch\n",
    "    from rockpool.nn.combinators import Sequential\n",
    "    import rockpool\n",
    "\n",
    "    benchmark_title = f\"Rockpool v{rockpool.__version__}\"\n",
    "\n",
    "    def prepare_fn(batch_size, n_steps, n_neurons, n_layers, device):\n",
    "        model = Sequential(\n",
    "            LinearTorch(shape=(n_neurons, n_neurons)),\n",
    "            LIFTorch(n_neurons),\n",
    "        ).to(device)\n",
    "        input_static = torch.randn(batch_size, n_steps, n_neurons).to(device)\n",
    "        with torch.no_grad():\n",
    "            model(input_static)\n",
    "        return dict(model=model, input=input_static, n_neurons=n_neurons)\n",
    "\n",
    "    def forward_fn(bench_dict):\n",
    "        model, input_static = bench_dict[\"model\"], bench_dict[\"input\"]\n",
    "        output = model(input_static)[0]\n",
    "        bench_dict[\"output\"] = output\n",
    "        return bench_dict\n",
    "\n",
    "    def backward_fn(bench_dict):\n",
    "        output = bench_dict[\"output\"]\n",
    "        loss = output.sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "    return prepare_fn, forward_fn, backward_fn, benchmark_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinabs():\n",
    "    from sinabs.layers import LIF\n",
    "    import sinabs\n",
    "    \n",
    "    benchmark_title = f\"Sinabs v{sinabs.__version__}\"\n",
    "\n",
    "    def prepare_fn(batch_size, n_steps, n_neurons, n_layers, device):\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n_neurons, n_neurons),\n",
    "            LIF(tau_mem=torch.tensor(10.0)),\n",
    "        ).to(device)\n",
    "        input_static = torch.randn(batch_size, n_steps, n_neurons).to(device)\n",
    "        with torch.no_grad():\n",
    "            model(input_static)\n",
    "        return dict(model=model, input=input_static, n_neurons=n_neurons)\n",
    "\n",
    "    def forward_fn(bench_dict):\n",
    "        model, input_static = bench_dict[\"model\"], bench_dict[\"input\"]\n",
    "        sinabs.reset_states(model)\n",
    "        bench_dict[\"output\"] = model(input_static)\n",
    "        return bench_dict\n",
    "\n",
    "    def backward_fn(bench_dict):\n",
    "        output = bench_dict[\"output\"]\n",
    "        loss = output.sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "    return prepare_fn, forward_fn, backward_fn, benchmark_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinabs_exodus():\n",
    "    from sinabs.exodus.layers import LIF\n",
    "    import sinabs\n",
    "\n",
    "    benchmark_title = f\"Sinabs EXODUS v{sinabs.exodus.__version__}\"\n",
    "\n",
    "    def prepare_fn(batch_size, n_steps, n_neurons, n_layers, device):\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(n_neurons, n_neurons),\n",
    "            LIF(tau_mem=torch.tensor(10.0)),\n",
    "        ).to(device)\n",
    "        input_static = torch.randn(batch_size, n_steps, n_neurons).to(device)\n",
    "        with torch.no_grad():\n",
    "            model(input_static)\n",
    "        return dict(model=model, input=input_static, n_neurons=n_neurons)\n",
    "\n",
    "    def forward_fn(bench_dict):\n",
    "        model, input_static = bench_dict[\"model\"], bench_dict[\"input\"]\n",
    "        sinabs.reset_states(model)\n",
    "        bench_dict[\"output\"] = model(input_static)\n",
    "        return bench_dict\n",
    "\n",
    "    def backward_fn(bench_dict):\n",
    "        output = bench_dict[\"output\"]\n",
    "        loss = output.sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "    return prepare_fn, forward_fn, backward_fn, benchmark_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norse():\n",
    "    from norse.torch.module.lif import LIF\n",
    "    from norse.torch import SequentialState\n",
    "    import norse\n",
    "\n",
    "    benchmark_title = f\"Norse v{norse.__version__}\"\n",
    "\n",
    "    def prepare_fn(batch_size, n_steps, n_neurons, n_layers, device):\n",
    "        model = SequentialState(\n",
    "            nn.Linear(n_neurons, n_neurons),\n",
    "            LIF(),\n",
    "        ).to(device)\n",
    "        input_static = torch.randn(n_steps, batch_size, n_neurons).to(device)\n",
    "        with torch.no_grad():\n",
    "            model(input_static)\n",
    "        return dict(model=model, input=input_static, n_neurons=n_neurons)\n",
    "\n",
    "    def forward_fn(bench_dict):\n",
    "        model, input_static = bench_dict[\"model\"], bench_dict[\"input\"]\n",
    "        bench_dict[\"output\"] = model(input_static)[0]\n",
    "        return bench_dict\n",
    "\n",
    "    def backward_fn(bench_dict):\n",
    "        output = bench_dict[\"output\"]\n",
    "        loss = output.sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "    return prepare_fn, forward_fn, backward_fn, benchmark_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def snntorch():\n",
    "    import snntorch\n",
    "\n",
    "    benchmark_title = f\"snnTorch v{snntorch.__version__}\"\n",
    "\n",
    "    def prepare_fn(batch_size, n_steps, n_neurons, n_layers, device):\n",
    "        class Model(nn.Module):\n",
    "            def __init__(self, beta: float = 0.95):\n",
    "                super().__init__()\n",
    "                self.fc =  nn.Linear(n_neurons, n_neurons)\n",
    "                self.lif = snntorch.Leaky(beta=beta)\n",
    "                self.mem = self.lif.init_leaky()\n",
    "            \n",
    "            def forward(self, x):\n",
    "                output = []\n",
    "                mem = self.mem\n",
    "                for inp in x:\n",
    "                    cur = self.fc(inp)\n",
    "                    spk, mem = self.lif(cur, mem)\n",
    "                    output.append(spk)\n",
    "                return torch.stack(output)\n",
    "\n",
    "        model = Model().to(device)\n",
    "        input_static = torch.randn(n_steps, batch_size, n_neurons).to(device)\n",
    "        with torch.no_grad():\n",
    "            model(input_static)\n",
    "        return dict(model=model, input=input_static, n_neurons=n_neurons)\n",
    "\n",
    "    def forward_fn(bench_dict):\n",
    "        model, input_static = bench_dict[\"model\"], bench_dict[\"input\"]\n",
    "        bench_dict[\"output\"] = model(input_static)[0]\n",
    "        return bench_dict\n",
    "\n",
    "    def backward_fn(bench_dict):\n",
    "        output = bench_dict[\"output\"]\n",
    "        loss = output.sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "    return prepare_fn, forward_fn, backward_fn, benchmark_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "n_steps = 100\n",
    "n_layers = 2\n",
    "n_neurons = 256\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for benchmark in [rockpool_torch, sinabs, sinabs_exodus, norse, snntorch]:\n",
    "# for benchmark in []:\n",
    "    prepare_fn, forward_fn, backward_fn, bench_desc = benchmark()\n",
    "    print(\"Benchmarking:\", bench_desc)\n",
    "    forward_times, backward_times = benchmark_framework(\n",
    "        prepare_fn=prepare_fn,\n",
    "        forward_fn=forward_fn,\n",
    "        backward_fn=backward_fn,\n",
    "        benchmark_desc=bench_desc,\n",
    "        n_neurons=n_neurons,\n",
    "        n_layers=n_layers,\n",
    "        n_steps=n_steps,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "    )\n",
    "    data.append([bench_desc, np.array(forward_times).flatten(), np.array(backward_times).flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"framework\", \"forward\", \"backward\",])\n",
    "df = df.explode('forward', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(df, x=\"framework\", y=\"forward\",)\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch\n",
    "\n",
    "beta = 0.9  # neuron decay rate\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_neurons, n_neurons),\n",
    "    snntorch.Leaky(beta=beta, init_hidden=True),\n",
    ").to(device)\n",
    "\n",
    "static_input = torch.randn(n_steps, batch_size, n_neurons).to(device)\n",
    "\n",
    "output = []\n",
    "for inp in static_input:\n",
    "    output.append(model(inp)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc =  nn.Linear(n_neurons, n_neurons).to(device)\n",
    "lif = snntorch.Leaky(beta=beta).to(device)\n",
    "mem = lif.init_leaky()\n",
    "\n",
    "output = []\n",
    "for inp in static_input:\n",
    "    cur = fc(inp) # post-synaptic current <-- spk_in x weight\n",
    "    spk, mem = lif(cur, mem) # mem[t+1] <--post-syn current + decayed membrane\n",
    "    output.append(spk)\n",
    "output = torch.stack(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare, forward, backward, desc = rockpool_torch()\n",
    "bench_dict = prepare(\n",
    "    batch_size=10,\n",
    "    n_steps=500,\n",
    "    n_neurons=512,\n",
    "    n_layers=4,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = bench_dict['model'](bench_dict['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rockpool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinabs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_backward_times[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sum().backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frameworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
